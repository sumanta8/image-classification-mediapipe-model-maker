{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "180833d6",
   "metadata": {},
   "source": [
    "Check tf version and GPU support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685dedbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aebb625",
   "metadata": {},
   "source": [
    "Initialize filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8328b4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './dataset'\n",
    "temp_dataset_path = './dataset-temp'\n",
    "exported_model_path = './exported-models'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8fe37d",
   "metadata": {},
   "source": [
    "Check if dataset is already present, if not create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ae246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    os.makedirs(dataset_path)\n",
    "    print(\"Dataset directory created\")\n",
    "else:\n",
    "    print(\"Dataset directory already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7a1b30",
   "metadata": {},
   "source": [
    "Download the Tiny ImageNet dataset if not already available. If the dataset directory is empty, the dataset will be downloaded from [https://cs231n.stanford.edu/tiny-imagenet-200.zip](https://cs231n.stanford.edu/tiny-imagenet-200.zip), extracted to a temporary folder, and prepared for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345ef4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "def download_file(url, destination):\n",
    "    response = requests.get(url, stream=True)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    \n",
    "    with open(destination, 'wb') as file, tqdm(\n",
    "        desc=destination,\n",
    "        total=total_size,\n",
    "        unit='iB',\n",
    "        unit_scale=True,\n",
    "        unit_divisor=1024,\n",
    "    ) as progress_bar:\n",
    "        for data in response.iter_content(chunk_size=1024):\n",
    "            size = file.write(data)\n",
    "            progress_bar.update(size)\n",
    "\n",
    "# Check if dataset directory is empty\n",
    "if not os.listdir(dataset_path):\n",
    "    # Replace with your actual dataset URL\n",
    "    dataset_url = \"https://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n",
    "    zip_path = \"./tiny-imagenet-200.zip\"\n",
    "\n",
    "    # Download and extract\n",
    "    print(\"Downloading dataset...\")\n",
    "    download_file(dataset_url, zip_path)\n",
    "\n",
    "    if not os.path.exists(temp_dataset_path):\n",
    "        os.makedirs(temp_dataset_path)\n",
    "        print(\"Temp dataset directory created\")\n",
    "    else:\n",
    "        print(\"Temp dataset directory already exists\")\n",
    "\n",
    "    print(\"Extracting dataset...\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(temp_dataset_path)\n",
    "\n",
    "    # Clean up zip file\n",
    "    os.remove(zip_path)\n",
    "    print(\"Dataset downloaded and extracted successfully\")\n",
    "else:\n",
    "    print(\"Dataset directory is not empty, skipping download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95af877a",
   "metadata": {},
   "source": [
    "Transform the Tiny ImageNet dataset into a hierarchical folder structure supported by MediaPipe Model Maker, where each class is represented by a folder named after its label (e.g., `tarantula`) inside the `./dataset` directory. Images for each class are copied into their respective folders, enabling easy ingestion for training custom image classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cf177c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "tiny_imagenet_path = f\"./{temp_dataset_path}/tiny-imagenet-200\"  # Path to the extracted Tiny ImageNet directory\n",
    "mp_train_data_path = dataset_path      # Path where you want to create the MediaPipe format data\n",
    "\n",
    "# Create the target directory if it doesn't exist\n",
    "os.makedirs(mp_train_data_path, exist_ok=True)\n",
    "\n",
    "# Load the word to WNID mapping\n",
    "words_path = os.path.join(tiny_imagenet_path, 'words.txt')\n",
    "wnid_to_words = {}\n",
    "with open(words_path, 'r') as f:\n",
    "    for line in f:\n",
    "        wnid, word = line.strip().split('\\t')\n",
    "        wnid_to_words[wnid] = word.split(',')[0].replace(' ', '_') # Use the first word and replace spaces with underscores\n",
    "\n",
    "train_path = os.path.join(tiny_imagenet_path, 'train')\n",
    "wnids = os.listdir(train_path)\n",
    "\n",
    "for wnid in wnids:\n",
    "    if os.path.isdir(os.path.join(train_path, wnid)):\n",
    "        image_folder = os.path.join(train_path, wnid, 'images')\n",
    "        if os.path.isdir(image_folder):\n",
    "            class_label = wnid_to_words.get(wnid)\n",
    "            if class_label:\n",
    "                target_class_folder = os.path.join(mp_train_data_path, class_label)\n",
    "                os.makedirs(target_class_folder, exist_ok=True)\n",
    "                for filename in os.listdir(image_folder):\n",
    "                    if filename.endswith('.JPEG'):\n",
    "                        source_path = os.path.join(image_folder, filename)\n",
    "                        destination_path = os.path.join(target_class_folder, filename)\n",
    "                        shutil.copy2(source_path, destination_path) # Copy images, preserving metadata\n",
    "                print(f\"Processed class: {class_label} ({wnid})\")\n",
    "            else:\n",
    "                print(f\"Warning: No word found for WNID: {wnid}\")\n",
    "\n",
    "print(\"Finished reorganizing the training data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c646931b",
   "metadata": {},
   "source": [
    "⚠️ **Warning:** Make sure to add the tray dataset in the `dataset` folder before proceeding. The tray dataset should go to `instrument-tray` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef8a248",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(dataset_path, 'instrument-tray')):\n",
    "    raise FileNotFoundError(\n",
    "        \"The 'instrument-tray' folder is missing in the dataset directory. \" \n",
    "        \"Please add the tray dataset to the 'instrument-tray' folder before proceeding.\"\n",
    "    )\n",
    "print(\"Found instrument-tray folder in the dataset directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb3d71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "export_folder_name = f\"./{exported_model_path}/trays_{timestamp}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bcff09",
   "metadata": {},
   "source": [
    "[Set retraining options](https://ai.google.dev/edge/mediapipe/solutions/customization/image_classifier#set_retraining_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e682e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mediapipe_model_maker import image_classifier\n",
    "spec = image_classifier.SupportedModels.EFFICIENTNET_LITE2\n",
    "hparams = image_classifier.HParams(export_dir=export_folder_name, batch_size=16)\n",
    "options = image_classifier.ImageClassifierOptions(supported_model=spec, hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc170c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(export_folder_name):\n",
    "    os.makedirs(export_folder_name, exist_ok=True)\n",
    "    print(f\"Export directory created: {export_folder_name}\")\n",
    "else:\n",
    "    print(f\"Export directory already exists: {export_folder_name}\")\n",
    "    # Optionally, you can add logic to handle existing directories (e.g., rename or skip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e16f37",
   "metadata": {},
   "source": [
    "[Create dataset](https://ai.google.dev/edge/mediapipe/solutions/customization/image_classifier#create_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139c00a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = dataset_path\n",
    "data = image_classifier.Dataset.from_folder(image_path)\n",
    "train_data, remaining_data = data.split(0.8)\n",
    "test_data, validation_data = remaining_data.split(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a04ae9",
   "metadata": {},
   "source": [
    "[Run retraining](https://ai.google.dev/edge/mediapipe/solutions/customization/image_classifier#run_retraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbefcb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = image_classifier.ImageClassifier.create(\n",
    "    train_data = train_data,\n",
    "    validation_data = validation_data,\n",
    "    options=options,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a97188d",
   "metadata": {},
   "source": [
    "[Evaluate performance](https://ai.google.dev/edge/mediapipe/solutions/customization/image_classifier#evaluate_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6462bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(test_data)\n",
    "print(f'Test loss:{loss}, Test accuracy:{acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5f7971",
   "metadata": {},
   "source": [
    "[Export model](https://ai.google.dev/edge/mediapipe/solutions/customization/image_classifier#export_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3be2549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mediapipe_model_maker import quantization\n",
    "quantization_config = quantization.QuantizationConfig.for_int8(train_data)\n",
    "model.export_model(model_name=f\"trays_model_{spec.name}.tflite\", quantization_config=quantization_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
